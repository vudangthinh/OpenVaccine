{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    data_dir = '../OpenVaccine/'\n",
    "    train_file = '../OpenVaccine/train.json'\n",
    "    test_file = '../OpenVaccine/test.json'\n",
    "    pretrain_dir = '../OpenVaccine/pretrains/'\n",
    "    sample_submission = '../OpenVaccine/sample_submission.csv'\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "    n_epoch = 100\n",
    "    n_split = 5\n",
    "    K = 1\n",
    "    gcn_agg = 'mean'\n",
    "    filter_noise = True\n",
    "    pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "    seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, aggregator='mean'):\n",
    "        super(GCN, self).__init__()\n",
    "        self.aggregator = aggregator\n",
    "        \n",
    "        if aggregator == 'mean':\n",
    "            linear_input_dim = input_dim * 2\n",
    "        elif aggregator == 'conv':\n",
    "            linear_input_dim = input_dim\n",
    "        elif aggregator == 'pooling':\n",
    "            linear_input_dim = input_dim * 2\n",
    "            self.linear_pooling = nn.Linear(input_dim, input_dim)\n",
    "        elif aggregator == 'lstm':\n",
    "            self.lstm_hidden = 128\n",
    "            linear_input_dim = input_dim + self.lstm_hidden\n",
    "            self.lstm_agg = nn.LSTM(input_dim, self.lstm_hidden, num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.linear_gcn = nn.Linear(in_features=linear_input_dim, out_features=output_dim)\n",
    "        \n",
    "    def forward(self, input_, adj_matrix):\n",
    "        if self.aggregator == 'conv':\n",
    "            # set elements in diagonal of adj matrix to 1 with conv aggregator\n",
    "            idx = torch.arange(0, adj_matrix.shape[-1], out=torch.LongTensor())\n",
    "            adj_matrix[:, idx, idx] = 1\n",
    "            \n",
    "        adj_matrix = adj_matrix.type(torch.float32)\n",
    "        sum_adj = torch.sum(adj_matrix, axis=2)\n",
    "        sum_adj[sum_adj==0] = 1\n",
    "        \n",
    "        if self.aggregator == 'mean' or self.aggregator == 'conv':\n",
    "            feature_agg = torch.bmm(adj_matrix, input_)\n",
    "            feature_agg = feature_agg / sum_adj.unsqueeze(dim=2)\n",
    "            \n",
    "        elif self.aggregator == 'pooling':\n",
    "            feature_pooling = self.linear_pooling(input_)\n",
    "            feature_agg = torch.sigmoid(feature_pooling)\n",
    "            feature_agg = torch.bmm(adj_matrix, feature_agg)\n",
    "            feature_agg = feature_agg / sum_adj.unsqueeze(dim=2)\n",
    "\n",
    "        elif self.aggregator == 'lstm':\n",
    "            feature_agg = torch.zeros(input_.shape[0], input_.shape[1], self.lstm_hidden).cuda()\n",
    "            for i in range(adj_matrix.shape[1]):\n",
    "                neighbors = adj_matrix[:, i, :].unsqueeze(2) * input_\n",
    "                _, hn = self.lstm_agg(neighbors)\n",
    "                feature_agg[:, i, :] = torch.squeeze(hn[0], 0)\n",
    "                \n",
    "        if self.aggregator != 'conv':\n",
    "            feature_cat = torch.cat((input_, feature_agg), axis=2)\n",
    "        else:\n",
    "            feature_cat = feature_agg\n",
    "                \n",
    "        feature = torch.sigmoid(self.linear_gcn(feature_cat))\n",
    "        feature = feature / torch.norm(feature, p=2, dim=2).unsqueeze(dim=2)\n",
    "        \n",
    "        return feature\n",
    "        \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_embedding=14, seq_len=107, pred_len=68, dropout=0.5, \n",
    "                 embed_dim=100, hidden_dim=128, K=1, aggregator='mean'):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.pred_len = pred_len\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=num_embedding, \n",
    "                                      embedding_dim=embed_dim)\n",
    "        \n",
    "        self.gcn = nn.ModuleList([GCN(3 * embed_dim, 3 * embed_dim, aggregator=aggregator) for i in range(K)])\n",
    "        \n",
    "        self.gru_layer = nn.GRU(input_size=3 * embed_dim, \n",
    "                          hidden_size=hidden_dim, \n",
    "                          num_layers=3, \n",
    "                          batch_first=True, \n",
    "                          dropout=dropout, \n",
    "                          bidirectional=True)\n",
    "        \n",
    "        self.linear_layer = nn.Linear(in_features=2 * hidden_dim, \n",
    "                                out_features=len(config.pred_cols))\n",
    "        \n",
    "    def forward(self, input_, adj_matrix):\n",
    "        #embedding\n",
    "        embedding = self.embedding_layer(input_)\n",
    "        embedding = torch.reshape(embedding, (-1, embedding.shape[1], embedding.shape[2] * embedding.shape[3]))\n",
    "        \n",
    "        #gcn\n",
    "        gcn_feature = embedding\n",
    "        for gcn_layer in self.gcn:\n",
    "            gcn_feature = gcn_layer(gcn_feature, adj_matrix)\n",
    "        \n",
    "        #gru\n",
    "        gru_output, gru_hidden = self.gru_layer(gcn_feature)\n",
    "        truncated = gru_output[:, :self.pred_len]\n",
    "        \n",
    "        output = self.linear_layer(truncated)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def get_couples(structure):\n",
    "    \"\"\"\n",
    "    For each closing parenthesis, I find the matching opening one and store their index in the couples list.\n",
    "    The assigned list is used to keep track of the assigned opening parenthesis\n",
    "    \"\"\"\n",
    "    opened = [idx for idx, i in enumerate(structure) if i == '(']\n",
    "    closed = [idx for idx, i in enumerate(structure) if i == ')']\n",
    "\n",
    "    assert len(opened) == len(closed)\n",
    "    assigned = []\n",
    "    couples = []\n",
    "\n",
    "    for close_idx in closed:\n",
    "        for open_idx in opened:\n",
    "            if open_idx < close_idx:\n",
    "                if open_idx not in assigned:\n",
    "                    candidate = open_idx\n",
    "            else:\n",
    "                break\n",
    "        assigned.append(candidate)\n",
    "        couples.append([candidate, close_idx])\n",
    "        \n",
    "    assert len(couples) == len(opened)\n",
    "    \n",
    "    return couples\n",
    "\n",
    "def build_matrix(couples, size):\n",
    "    mat = np.zeros((size, size))\n",
    "    \n",
    "    for i in range(size):  # neigbouring bases are linked as well\n",
    "        if i < size - 1:\n",
    "            mat[i, i + 1] = 1\n",
    "        if i > 0:\n",
    "            mat[i, i - 1] = 1\n",
    "    \n",
    "    for i, j in couples:\n",
    "        mat[i, j] = 1\n",
    "        mat[j, i] = 1\n",
    "        \n",
    "    return mat\n",
    "\n",
    "def convert_to_adj(structure):\n",
    "    couples = get_couples(structure)\n",
    "    mat = build_matrix(couples, len(structure))\n",
    "    return mat\n",
    "\n",
    "def bpp_to_adj(id):\n",
    "    bpp_file = f'{config.data_dir}/bpps/{id}.npy'\n",
    "    bpp = np.load(bpp_file)\n",
    "    adj = bpp\n",
    "#     adj = np.where(bpp > 0, 1, 0)\n",
    "    return adj\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    inputs = np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )\n",
    "    \n",
    "    adj_matrix = np.array(df['structure'].apply(convert_to_adj).values.tolist())\n",
    "#     adj_matrix = np.array(df['id'].apply(bpp_to_adj).values.tolist())\n",
    "    \n",
    "    return inputs, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(config.train_file, lines=True)\n",
    "\n",
    "if config.filter_noise:\n",
    "    train = train[train.SN_filter == 1]\n",
    "    \n",
    "test = pd.read_json(config.test_file, lines=True)\n",
    "sample_df = pd.read_csv(config.sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_adj = preprocess_inputs(train)\n",
    "train_labels = np.array(train[config.pred_cols].values.tolist()).transpose((0, 2, 1))\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n",
    "train_adj = torch.tensor(train_adj, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(epoch, model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    train_loss = AverageMeter()\n",
    "    \n",
    "    for index, (input_, adj, label) in enumerate(train_loader):\n",
    "        input_ = input_.cuda()\n",
    "        adj = adj.cuda()\n",
    "        label = label.cuda()\n",
    "        preds = model(input_, adj)\n",
    "        \n",
    "        loss = criterion(preds, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.update(loss.item())\n",
    "    \n",
    "    print(f\"Train loss {train_loss.avg}\")\n",
    "    return train_loss.avg\n",
    "    \n",
    "def eval_fn(epoch, model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    eval_loss = AverageMeter()\n",
    "    oof_label = None\n",
    "    oof_pred = None\n",
    "    \n",
    "    for index, (input_, adj, label) in enumerate(valid_loader):\n",
    "        input_ = input_.cuda()\n",
    "        adj = adj.cuda()\n",
    "        label = label.cuda()\n",
    "        preds = model(input_, adj)\n",
    "        \n",
    "        loss = criterion(preds, label)\n",
    "        eval_loss.update(loss.item())\n",
    "        if oof_label is None:\n",
    "            oof_label = label.cpu().detach()\n",
    "            oof_pred = preds.cpu().detach()\n",
    "        else:\n",
    "            oof_label = torch.cat([oof_label, label.cpu().detach()], 0)\n",
    "            oof_pred = torch.cat([oof_pred, preds.cpu().detach()], 0)\n",
    "    \n",
    "    print(f\"Valid loss {eval_loss.avg}\")\n",
    "    return eval_loss.avg, oof_label, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = torch.mean(torch.square(y_true - y_pred), axis=1)\n",
    "    return torch.mean(torch.sqrt(colwise_mse))\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = torch.nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss\n",
    "    \n",
    "class MCRMSELoss(nn.Module):\n",
    "    def __init__(self, num_scored=3):\n",
    "        super().__init__()\n",
    "        self.rmse = RMSELoss()\n",
    "        self.num_scored = num_scored\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        score = 0\n",
    "        for i in range(self.num_scored):\n",
    "            score += self.rmse(yhat[:, :, i], y[:, :, i]) / self.num_scored\n",
    "\n",
    "        return score\n",
    "    \n",
    "def run(fold, train_loader, valid_loader):\n",
    "    model = Net(K=config.K, aggregator=config.gcn_agg)\n",
    "    model.cuda()\n",
    "    criterion = MCRMSE # MCRMSELoss(num_scored=5) #torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=config.learning_rate, weight_decay=0.0)\n",
    "    \n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    for epoch in range(config.n_epoch):\n",
    "        print('#################')\n",
    "        print('###Epoch:', epoch)\n",
    "        \n",
    "        train_loss = train_fn(epoch, model, train_loader, criterion, optimizer)\n",
    "        eval_loss, oof_label, oof_pred = eval_fn(epoch, model, valid_loader, criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        eval_losses.append(eval_loss)\n",
    "        \n",
    "    torch.save(model.state_dict(), f'{config.pretrain_dir}/gru_{fold}.pt')\n",
    "    return train_losses, eval_losses, oof_label, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.4736518368124962\n",
      "Valid loss 0.41888638734817507\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.40256469547748563\n",
      "Valid loss 0.37292989492416384\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.3741307511925697\n",
      "Valid loss 0.35383965969085696\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.3538067176938057\n",
      "Valid loss 0.33535735607147216\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.3359106555581093\n",
      "Valid loss 0.33099058270454407\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.32673446387052535\n",
      "Valid loss 0.31456226110458374\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.31805810928344724\n",
      "Valid loss 0.307984322309494\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.31302081793546677\n",
      "Valid loss 0.3049154162406921\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.3086333736777306\n",
      "Valid loss 0.3012210190296173\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.304643914103508\n",
      "Valid loss 0.2953181266784668\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.30137674808502196\n",
      "Valid loss 0.29262409210205076\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.2964195281267166\n",
      "Valid loss 0.2902895987033844\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.2937294334173203\n",
      "Valid loss 0.28750465512275697\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.2883778363466263\n",
      "Valid loss 0.2813497960567474\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.28317662328481674\n",
      "Valid loss 0.2734537720680237\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.28066480755805967\n",
      "Valid loss 0.27265608310699463\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.27576428800821307\n",
      "Valid loss 0.2659049332141876\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.27171085625886915\n",
      "Valid loss 0.26283499598503113\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.26796987652778625\n",
      "Valid loss 0.2625658392906189\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.2664884299039841\n",
      "Valid loss 0.25921912789344786\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.26514934226870535\n",
      "Valid loss 0.257137268781662\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.26178420409560205\n",
      "Valid loss 0.2534147083759308\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.25773356258869173\n",
      "Valid loss 0.2516420274972916\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.25452438816428186\n",
      "Valid loss 0.25111892223358157\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.25362774506211283\n",
      "Valid loss 0.24650681316852568\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.25092531442642213\n",
      "Valid loss 0.24908184111118317\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.24987047761678696\n",
      "Valid loss 0.24800348281860352\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.24631759971380235\n",
      "Valid loss 0.24217309951782226\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.24474335014820098\n",
      "Valid loss 0.24246449172496795\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.2457867980003357\n",
      "Valid loss 0.23952678143978118\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.241735353320837\n",
      "Valid loss 0.2371221661567688\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.2382698804140091\n",
      "Valid loss 0.23951562047004699\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.23972033336758614\n",
      "Valid loss 0.23727916479110717\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.23695721626281738\n",
      "Valid loss 0.23615410327911376\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.23607883155345916\n",
      "Valid loss 0.23705412745475768\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.23443109393119813\n",
      "Valid loss 0.2343096911907196\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.23234559819102288\n",
      "Valid loss 0.23356486856937408\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.23236995115876197\n",
      "Valid loss 0.2330867439508438\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.2315089486539364\n",
      "Valid loss 0.2358363926410675\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.22940397933125495\n",
      "Valid loss 0.23153490722179412\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.22907346710562707\n",
      "Valid loss 0.23223420083522797\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.2297792427241802\n",
      "Valid loss 0.23081089556217194\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.2278496094048023\n",
      "Valid loss 0.23187829852104186\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.22585486620664597\n",
      "Valid loss 0.22828181385993956\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.22390928864479065\n",
      "Valid loss 0.23132905960083008\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.22325391247868537\n",
      "Valid loss 0.22910463213920593\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.22171987667679788\n",
      "Valid loss 0.226067852973938\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.21949797719717026\n",
      "Valid loss 0.2244085967540741\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.21909885704517365\n",
      "Valid loss 0.22654357850551604\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.21923451423645018\n",
      "Valid loss 0.22579785883426667\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.21776931434869767\n",
      "Valid loss 0.22331435978412628\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.2167045697569847\n",
      "Valid loss 0.22405749857425689\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.21573567911982536\n",
      "Valid loss 0.22338669896125793\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.21524777114391327\n",
      "Valid loss 0.22752552032470702\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.21402988955378532\n",
      "Valid loss 0.22457462847232817\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.21311961188912393\n",
      "Valid loss 0.2225245475769043\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.21215712949633597\n",
      "Valid loss 0.22453600466251372\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.21171193569898605\n",
      "Valid loss 0.22238527834415436\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.21098995357751846\n",
      "Valid loss 0.22057293951511384\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.21039167642593384\n",
      "Valid loss 0.2206269085407257\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.20859613120555878\n",
      "Valid loss 0.22028410136699678\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.2088032990694046\n",
      "Valid loss 0.22224872708320617\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.207821337133646\n",
      "Valid loss 0.22031773924827575\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.207151560485363\n",
      "Valid loss 0.22024548649787903\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.20672885775566102\n",
      "Valid loss 0.22322776019573212\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.2056316278874874\n",
      "Valid loss 0.22015124261379243\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.20515583828091621\n",
      "Valid loss 0.2209552615880966\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.20455331206321717\n",
      "Valid loss 0.22011714279651642\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.203205356746912\n",
      "Valid loss 0.22036286294460297\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.20201725214719773\n",
      "Valid loss 0.22428429126739502\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.20175227299332618\n",
      "Valid loss 0.2226084887981415\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.20138718858361243\n",
      "Valid loss 0.2177139163017273\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.19989713057875633\n",
      "Valid loss 0.21980894804000856\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.20023196190595627\n",
      "Valid loss 0.2186611533164978\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.1988339528441429\n",
      "Valid loss 0.2188320428133011\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.19825347140431404\n",
      "Valid loss 0.22025977373123168\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.19793718233704566\n",
      "Valid loss 0.21892671883106232\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.1966365806758404\n",
      "Valid loss 0.21803057491779326\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.19698477759957314\n",
      "Valid loss 0.21931492984294892\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.19575930163264274\n",
      "Valid loss 0.2186554729938507\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.19535017088055612\n",
      "Valid loss 0.21769083738327027\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.194608623534441\n",
      "Valid loss 0.21942033767700195\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.19449029341340066\n",
      "Valid loss 0.21792614758014678\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.19342898651957513\n",
      "Valid loss 0.21796190738677979\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.1932097963988781\n",
      "Valid loss 0.2176802098751068\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.1923821084201336\n",
      "Valid loss 0.21717361211776734\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.19189042523503302\n",
      "Valid loss 0.21716111302375793\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.19144887700676919\n",
      "Valid loss 0.2200135111808777\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.19068554788827896\n",
      "Valid loss 0.21661048829555513\n",
      "#################\n",
      "###Epoch: 89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.19137678891420365\n",
      "Valid loss 0.21653702855110168\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.19023684561252593\n",
      "Valid loss 0.2167837530374527\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.1896523840725422\n",
      "Valid loss 0.21967997252941132\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.18934932202100754\n",
      "Valid loss 0.21901734471321105\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.18840970620512962\n",
      "Valid loss 0.21635543406009675\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.18871036544442177\n",
      "Valid loss 0.2182433396577835\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.1875872418284416\n",
      "Valid loss 0.21841321885585785\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.1866515427827835\n",
      "Valid loss 0.215856671333313\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.18727300241589545\n",
      "Valid loss 0.21898153722286223\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.18649930730462075\n",
      "Valid loss 0.21650962829589843\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.18656896129250528\n",
      "Valid loss 0.21737924516201018\n",
      "Last 5 epoch train: 0.1869160111248493 - valid: 0.21742806017398836\n",
      "Last 10 epoch train: 0.18809386789798738 - valid: 0.21772201448678968\n",
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.47064208835363386\n",
      "Valid loss 0.4180183410644531\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.3936318323016167\n",
      "Valid loss 0.3840706169605255\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.37093831449747083\n",
      "Valid loss 0.3627558290958405\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.3538270428776741\n",
      "Valid loss 0.34675406813621523\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.33833544999361037\n",
      "Valid loss 0.33611330986022947\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.32777465879917145\n",
      "Valid loss 0.32331339120864866\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.31864322274923323\n",
      "Valid loss 0.3178825259208679\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.3116282418370247\n",
      "Valid loss 0.3116652727127075\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.30641849189996717\n",
      "Valid loss 0.3070402264595032\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.3021645411849022\n",
      "Valid loss 0.30430108308792114\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.2978500038385391\n",
      "Valid loss 0.29782905578613283\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.2914766654372215\n",
      "Valid loss 0.29261507987976076\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.28780360966920854\n",
      "Valid loss 0.2908717691898346\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.2841675341129303\n",
      "Valid loss 0.287514454126358\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.2809107840061188\n",
      "Valid loss 0.2811566233634949\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.2754571378231049\n",
      "Valid loss 0.2793479681015015\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.2730410903692245\n",
      "Valid loss 0.27843008041381834\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.27055965512990954\n",
      "Valid loss 0.27196982502937317\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.267420269548893\n",
      "Valid loss 0.27119665741920473\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.2650279991328716\n",
      "Valid loss 0.26858587861061095\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.26214794665575025\n",
      "Valid loss 0.26582711935043335\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.25771945863962176\n",
      "Valid loss 0.26302026510238646\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.2542751245200634\n",
      "Valid loss 0.2585228502750397\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.2534219235181808\n",
      "Valid loss 0.25781115889549255\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.25089231580495835\n",
      "Valid loss 0.25551643669605256\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.2472720317542553\n",
      "Valid loss 0.2557676792144775\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.24756795391440392\n",
      "Valid loss 0.2538477867841721\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.24388960376381874\n",
      "Valid loss 0.25098968148231504\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.24256621524691582\n",
      "Valid loss 0.2489698648452759\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.24083878919482232\n",
      "Valid loss 0.24742333889007567\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.24003295972943306\n",
      "Valid loss 0.24603849947452544\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.23961760997772216\n",
      "Valid loss 0.2503312945365906\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.23590550050139428\n",
      "Valid loss 0.24438313841819764\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.23444350063800812\n",
      "Valid loss 0.24250471591949463\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.2352720730006695\n",
      "Valid loss 0.24482145607471467\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.2323092795908451\n",
      "Valid loss 0.24164949655532836\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.2301060251891613\n",
      "Valid loss 0.2405695855617523\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.22968372330069542\n",
      "Valid loss 0.24438480138778687\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.23028575405478477\n",
      "Valid loss 0.238196063041687\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.22867244556546212\n",
      "Valid loss 0.23840587437152863\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.22673074379563332\n",
      "Valid loss 0.23641761839389802\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.22480892688035964\n",
      "Valid loss 0.23804646134376525\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.22415149509906768\n",
      "Valid loss 0.23475333154201508\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.22286346331238746\n",
      "Valid loss 0.23558516800403595\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.223230017721653\n",
      "Valid loss 0.23534063696861268\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.22166183739900588\n",
      "Valid loss 0.2349971979856491\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.22117100581526755\n",
      "Valid loss 0.23946878015995027\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.22132197320461272\n",
      "Valid loss 0.23404118716716765\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.21859277486801149\n",
      "Valid loss 0.2327185183763504\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.21776327043771743\n",
      "Valid loss 0.23247006237506868\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.21822569891810417\n",
      "Valid loss 0.23180451691150666\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.21573857590556145\n",
      "Valid loss 0.22977463603019715\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.214780542999506\n",
      "Valid loss 0.23048346042633056\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.21410319805145264\n",
      "Valid loss 0.23125501573085785\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.21477383226156235\n",
      "Valid loss 0.2303783416748047\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.2138750396668911\n",
      "Valid loss 0.2307539701461792\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.21110727787017822\n",
      "Valid loss 0.2290635883808136\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.2106720082461834\n",
      "Valid loss 0.22798218131065368\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.20984452366828918\n",
      "Valid loss 0.23248687386512756\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.21076911464333534\n",
      "Valid loss 0.23356034457683564\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.20998159497976304\n",
      "Valid loss 0.2269201934337616\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.2081025630235672\n",
      "Valid loss 0.22687641978263856\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.20731866136193275\n",
      "Valid loss 0.23040030300617217\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.2073102191090584\n",
      "Valid loss 0.22933409810066224\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.20611874833703042\n",
      "Valid loss 0.2266155630350113\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.2045698881149292\n",
      "Valid loss 0.2256487101316452\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.2056022621691227\n",
      "Valid loss 0.22563569545745848\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.205403883010149\n",
      "Valid loss 0.22616638541221618\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.20435307323932647\n",
      "Valid loss 0.2253139853477478\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.20211731866002083\n",
      "Valid loss 0.22509985864162446\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.20152578130364418\n",
      "Valid loss 0.22521311938762664\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.20139408335089684\n",
      "Valid loss 0.22531741559505464\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.20114832371473312\n",
      "Valid loss 0.22495108246803283\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.20027078837156295\n",
      "Valid loss 0.22693871557712555\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.19964745715260507\n",
      "Valid loss 0.22615158259868623\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.19877140894532203\n",
      "Valid loss 0.22515991926193238\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.19794081076979636\n",
      "Valid loss 0.22335803508758545\n",
      "#################\n",
      "###Epoch: 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.19731983095407485\n",
      "Valid loss 0.22326373755931855\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.19700249582529067\n",
      "Valid loss 0.22562285363674164\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.1967194303870201\n",
      "Valid loss 0.22315486371517182\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.19572677239775657\n",
      "Valid loss 0.22158203423023223\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.1951096959412098\n",
      "Valid loss 0.22384800612926484\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.194117022305727\n",
      "Valid loss 0.22162909507751466\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.1937007375061512\n",
      "Valid loss 0.22186661660671234\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.19414836615324021\n",
      "Valid loss 0.22328489124774933\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.19338174313306808\n",
      "Valid loss 0.22353942096233367\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.19236019775271415\n",
      "Valid loss 0.2221648007631302\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.1918291375041008\n",
      "Valid loss 0.22426466047763824\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.1913781002163887\n",
      "Valid loss 0.22377009987831115\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.1910702459514141\n",
      "Valid loss 0.2222241073846817\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.19130579233169556\n",
      "Valid loss 0.2230134576559067\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.19067387804389\n",
      "Valid loss 0.22413105368614197\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.18977319374680518\n",
      "Valid loss 0.22030096054077147\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.19012159779667853\n",
      "Valid loss 0.22003526091575623\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.188987198472023\n",
      "Valid loss 0.22200545072555541\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.1880369707942009\n",
      "Valid loss 0.22111473083496094\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.18686491698026658\n",
      "Valid loss 0.21918124556541443\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.1866314508020878\n",
      "Valid loss 0.21964138746261597\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.18579567447304726\n",
      "Valid loss 0.22094343304634095\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.18532488569617273\n",
      "Valid loss 0.21990676820278168\n",
      "Last 5 epoch train: 0.18653077974915505 - valid: 0.22015751302242278\n",
      "Last 10 epoch train: 0.18835155591368677 - valid: 0.2210273748636246\n",
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.46933130323886874\n",
      "Valid loss 0.4121465146541595\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.39648217260837554\n",
      "Valid loss 0.37762396335601806\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.3724246725440025\n",
      "Valid loss 0.3577690660953522\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.3530616208910942\n",
      "Valid loss 0.33600581884384156\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.3355400308966637\n",
      "Valid loss 0.3214856207370758\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.3248194620013237\n",
      "Valid loss 0.31648815274238584\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.3190054789185524\n",
      "Valid loss 0.30972795486450194\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.31122607439756395\n",
      "Valid loss 0.30424465537071227\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.30672342926263807\n",
      "Valid loss 0.30439687967300416\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.30154844671487807\n",
      "Valid loss 0.29557905793190004\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.2977792486548424\n",
      "Valid loss 0.2913843870162964\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.29144526720047\n",
      "Valid loss 0.28750171065330504\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.2877838611602783\n",
      "Valid loss 0.28340756297111513\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.2840037509799004\n",
      "Valid loss 0.27766077518463134\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.2802321970462799\n",
      "Valid loss 0.27442771196365356\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.2748262122273445\n",
      "Valid loss 0.27060035467147825\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.2728761598467827\n",
      "Valid loss 0.2743429481983185\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.27132550030946734\n",
      "Valid loss 0.2655590534210205\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.26793480664491653\n",
      "Valid loss 0.2650236845016479\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.26434612423181536\n",
      "Valid loss 0.26257902979850767\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.26141170114278794\n",
      "Valid loss 0.25685315728187563\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.2597749881446362\n",
      "Valid loss 0.25670293569564817\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.2576411746442318\n",
      "Valid loss 0.254339274764061\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.2556090861558914\n",
      "Valid loss 0.25498913824558256\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.25505407601594926\n",
      "Valid loss 0.2534371465444565\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.25121656656265257\n",
      "Valid loss 0.2501127541065216\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.2496298983693123\n",
      "Valid loss 0.24692333340644837\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.2472536213696003\n",
      "Valid loss 0.24467450082302095\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.24547398835420609\n",
      "Valid loss 0.24495308995246887\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.24277607202529908\n",
      "Valid loss 0.24114422202110292\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.24028342664241792\n",
      "Valid loss 0.24273210167884826\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.23929195255041122\n",
      "Valid loss 0.2402125209569931\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.2396605834364891\n",
      "Valid loss 0.24142488539218904\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.23697883412241935\n",
      "Valid loss 0.23731581270694732\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.23577697426080704\n",
      "Valid loss 0.23598270416259765\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.23379693999886514\n",
      "Valid loss 0.23534055054187775\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.23299957439303398\n",
      "Valid loss 0.2344174861907959\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.23194340243935585\n",
      "Valid loss 0.2334587574005127\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.2307723045349121\n",
      "Valid loss 0.23453942835330963\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.2292758472263813\n",
      "Valid loss 0.23543899655342101\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.22968839854002\n",
      "Valid loss 0.23324937820434571\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.22653695195913315\n",
      "Valid loss 0.23029065132141113\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.2255573995411396\n",
      "Valid loss 0.23324609100818633\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.22579919323325157\n",
      "Valid loss 0.2295634150505066\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.2243694469332695\n",
      "Valid loss 0.23219152092933654\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.22223587408661843\n",
      "Valid loss 0.22819401323795319\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.22102546617388724\n",
      "Valid loss 0.22962741553783417\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.2199575997889042\n",
      "Valid loss 0.2275266617536545\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.21912508308887482\n",
      "Valid loss 0.22570698261260985\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.2181524708867073\n",
      "Valid loss 0.22479669749736786\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.21760227680206298\n",
      "Valid loss 0.22578676044940948\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.21728154718875886\n",
      "Valid loss 0.22678999602794647\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.21564938873052597\n",
      "Valid loss 0.22413719594478607\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.2151276908814907\n",
      "Valid loss 0.2279600203037262\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.2148670732975006\n",
      "Valid loss 0.22565231323242188\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.21295396313071252\n",
      "Valid loss 0.2229997545480728\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.21386317312717437\n",
      "Valid loss 0.2235935240983963\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.21215458884835242\n",
      "Valid loss 0.22508209347724914\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.21024708822369576\n",
      "Valid loss 0.2217007488012314\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.20952108949422837\n",
      "Valid loss 0.2234998881816864\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.20904595032334328\n",
      "Valid loss 0.22236455380916595\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.208075600117445\n",
      "Valid loss 0.222214737534523\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.20723652094602585\n",
      "Valid loss 0.2221665233373642\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.20795629695057868\n",
      "Valid loss 0.2228122264146805\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.2070298194885254\n",
      "Valid loss 0.22145932018756867\n",
      "#################\n",
      "###Epoch: 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.2053619660437107\n",
      "Valid loss 0.21968188285827636\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.2042568065226078\n",
      "Valid loss 0.22228715419769288\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.2048453189432621\n",
      "Valid loss 0.2203601211309433\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.20389125049114226\n",
      "Valid loss 0.2202998638153076\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.2027270309627056\n",
      "Valid loss 0.21995292901992797\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.2023948110640049\n",
      "Valid loss 0.21831955909729003\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.20151490420103074\n",
      "Valid loss 0.2194102495908737\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.2011263146996498\n",
      "Valid loss 0.21895726323127745\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.20000938847661018\n",
      "Valid loss 0.22084712088108063\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.19889691472053528\n",
      "Valid loss 0.21895231902599335\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.1991618812084198\n",
      "Valid loss 0.21850109100341797\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.19831802174448968\n",
      "Valid loss 0.21864886581897736\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.19781205281615258\n",
      "Valid loss 0.2192734330892563\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.19700696021318437\n",
      "Valid loss 0.21781077980995178\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.19625866115093232\n",
      "Valid loss 0.21935113668441772\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.19652016013860701\n",
      "Valid loss 0.2174658864736557\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.1950433671474457\n",
      "Valid loss 0.2188216656446457\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.19521648585796356\n",
      "Valid loss 0.2194929301738739\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.19506918489933014\n",
      "Valid loss 0.21856523156166077\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.1949087545275688\n",
      "Valid loss 0.2206488937139511\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.19480419754981995\n",
      "Valid loss 0.21834135949611663\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.19270054176449775\n",
      "Valid loss 0.2176705539226532\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.19208482652902603\n",
      "Valid loss 0.21633095443248748\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.1916447661817074\n",
      "Valid loss 0.21840106844902038\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.19128343611955642\n",
      "Valid loss 0.21663338243961333\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.1916922524571419\n",
      "Valid loss 0.21677061915397644\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.19149193540215492\n",
      "Valid loss 0.21841822266578675\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.18963665887713432\n",
      "Valid loss 0.21824209988117219\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.19005851447582245\n",
      "Valid loss 0.2187347650527954\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.18902256861329078\n",
      "Valid loss 0.21824389100074768\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.18827126547694206\n",
      "Valid loss 0.2181257873773575\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.18770787864923477\n",
      "Valid loss 0.2179540812969208\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.18677912279963493\n",
      "Valid loss 0.21765660047531127\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.18707669973373414\n",
      "Valid loss 0.21737001240253448\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.1862914077937603\n",
      "Valid loss 0.2163078099489212\n",
      "Last 5 epoch train: 0.18722527489066124 - valid: 0.21748285830020903\n",
      "Last 10 epoch train: 0.18880283042788507 - valid: 0.21778238892555235\n",
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.46763780415058137\n",
      "Valid loss 0.41885835528373716\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.3935707971453667\n",
      "Valid loss 0.3813323199748993\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.3706353634595871\n",
      "Valid loss 0.361658102273941\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.3524187982082367\n",
      "Valid loss 0.3420164942741394\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.33361699879169465\n",
      "Valid loss 0.3256732761859894\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.3236266776919365\n",
      "Valid loss 0.3174822747707367\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.3161775693297386\n",
      "Valid loss 0.3166883111000061\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.31065772473812103\n",
      "Valid loss 0.30800567865371703\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.3063186928629875\n",
      "Valid loss 0.3052612543106079\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.3039051964879036\n",
      "Valid loss 0.3019016206264496\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.29854004383087157\n",
      "Valid loss 0.2970950186252594\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.2936242312192917\n",
      "Valid loss 0.2944557309150696\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.29114861935377123\n",
      "Valid loss 0.292728978395462\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.2862440586090088\n",
      "Valid loss 0.28129732608795166\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.2793269857764244\n",
      "Valid loss 0.27980437874794006\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.2758610054850578\n",
      "Valid loss 0.2778042435646057\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.2725067898631096\n",
      "Valid loss 0.2826781332492828\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.26921585500240325\n",
      "Valid loss 0.2709830105304718\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.26524140387773515\n",
      "Valid loss 0.26694273948669434\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.2617702573537827\n",
      "Valid loss 0.26348737478256223\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.26060531064867976\n",
      "Valid loss 0.266226202249527\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.25961959958076475\n",
      "Valid loss 0.26431127786636355\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.256022734194994\n",
      "Valid loss 0.2610353887081146\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.2542410269379616\n",
      "Valid loss 0.25612770318984984\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.2519382208585739\n",
      "Valid loss 0.2566333174705505\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.24936212375760078\n",
      "Valid loss 0.2585762321949005\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.24840188547968864\n",
      "Valid loss 0.2517718881368637\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.2460131861269474\n",
      "Valid loss 0.2525475174188614\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.24382030591368675\n",
      "Valid loss 0.249556827545166\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.242215096950531\n",
      "Valid loss 0.24960595071315766\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.24028802663087845\n",
      "Valid loss 0.2509212166070938\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.24149290174245835\n",
      "Valid loss 0.25230743288993834\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.23820180669426919\n",
      "Valid loss 0.24586396515369416\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.23478675186634063\n",
      "Valid loss 0.24548440277576447\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.2346293196082115\n",
      "Valid loss 0.24319348931312562\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.2325596332550049\n",
      "Valid loss 0.2422545701265335\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.23064707070589066\n",
      "Valid loss 0.2417957752943039\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.2302229106426239\n",
      "Valid loss 0.24208978712558746\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.23112188130617142\n",
      "Valid loss 0.24385067224502563\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.22903460562229155\n",
      "Valid loss 0.24054800868034362\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.22578348144888877\n",
      "Valid loss 0.23872418105602264\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.22585055455565453\n",
      "Valid loss 0.23891640603542327\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.22718634456396103\n",
      "Valid loss 0.24251298904418944\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.22495334818959237\n",
      "Valid loss 0.23977888226509095\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.22269686236977576\n",
      "Valid loss 0.23825934529304504\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.22175424098968505\n",
      "Valid loss 0.23753122687339784\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.22072644382715226\n",
      "Valid loss 0.23621298670768737\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.22036812528967858\n",
      "Valid loss 0.23777411580085756\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.2201714724302292\n",
      "Valid loss 0.24026557207107543\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.21870051994919776\n",
      "Valid loss 0.23533116281032562\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.21776900961995124\n",
      "Valid loss 0.23434600830078126\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.21638420447707177\n",
      "Valid loss 0.2336270898580551\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.2154629960656166\n",
      "Valid loss 0.23323355615139008\n",
      "#################\n",
      "###Epoch: 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.21353540495038031\n",
      "Valid loss 0.2347470462322235\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.21419822573661804\n",
      "Valid loss 0.23242753148078918\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.21261354833841323\n",
      "Valid loss 0.2311989575624466\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.21099662482738496\n",
      "Valid loss 0.23275499641895295\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.2107037477195263\n",
      "Valid loss 0.23236227929592132\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.2102730877697468\n",
      "Valid loss 0.23277421295642853\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.20978924185037612\n",
      "Valid loss 0.2306637465953827\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.2085300363600254\n",
      "Valid loss 0.23120792508125304\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.20801911279559135\n",
      "Valid loss 0.23092640936374664\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.20676039382815362\n",
      "Valid loss 0.23051493763923644\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.20555393770337105\n",
      "Valid loss 0.23307294249534607\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.2054966740310192\n",
      "Valid loss 0.22942609786987306\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.20421036183834076\n",
      "Valid loss 0.22984201312065125\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.20327213183045387\n",
      "Valid loss 0.23020905554294585\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.20285462886095046\n",
      "Valid loss 0.22911207973957062\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.20285984501242638\n",
      "Valid loss 0.22851473093032837\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.20168749168515204\n",
      "Valid loss 0.23023856282234192\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.20217027142643929\n",
      "Valid loss 0.22743623256683348\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.2012949138879776\n",
      "Valid loss 0.22741717100143433\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.2000512771308422\n",
      "Valid loss 0.2284375548362732\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.19905645176768302\n",
      "Valid loss 0.22648104131221772\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.19850073605775834\n",
      "Valid loss 0.2284865587949753\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.1985790602862835\n",
      "Valid loss 0.2268265575170517\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.19757717698812485\n",
      "Valid loss 0.22848515212535858\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.19702475517988205\n",
      "Valid loss 0.2307045876979828\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.19599223881959915\n",
      "Valid loss 0.22726220190525054\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.19567062258720397\n",
      "Valid loss 0.22687525153160096\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.1949767328798771\n",
      "Valid loss 0.2275427132844925\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.1942846529185772\n",
      "Valid loss 0.22908499240875244\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.19412477537989617\n",
      "Valid loss 0.22732807397842408\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.19440064281225206\n",
      "Valid loss 0.2285011440515518\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.19290645197033882\n",
      "Valid loss 0.22827427685260773\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.1925757646560669\n",
      "Valid loss 0.22699546813964844\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.19177931174635887\n",
      "Valid loss 0.22750756442546843\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.192137161642313\n",
      "Valid loss 0.22445695400238036\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.1906930074095726\n",
      "Valid loss 0.22887403070926665\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.19008858427405356\n",
      "Valid loss 0.22620235979557038\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.18954622372984886\n",
      "Valid loss 0.2282101809978485\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.1888885095715523\n",
      "Valid loss 0.22603238821029664\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.1887062631547451\n",
      "Valid loss 0.2258783221244812\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.18906600549817085\n",
      "Valid loss 0.2264011949300766\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.1879064477980137\n",
      "Valid loss 0.22426562905311584\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.18686226308345794\n",
      "Valid loss 0.2284051865339279\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.18686133921146392\n",
      "Valid loss 0.22563720643520355\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.186685162037611\n",
      "Valid loss 0.22693473994731903\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.18584148585796356\n",
      "Valid loss 0.22472235262393953\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.18600952848792077\n",
      "Valid loss 0.225842621922493\n",
      "Last 5 epoch train: 0.18645195573568343 - valid: 0.22630842149257657\n",
      "Last 10 epoch train: 0.18763732284307483 - valid: 0.2262329822778702\n",
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.48334712237119676\n",
      "Valid loss 0.4233414590358734\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.4079539209604263\n",
      "Valid loss 0.37244551777839663\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.37772530168294904\n",
      "Valid loss 0.3557551860809326\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.35905726701021196\n",
      "Valid loss 0.3357693612575531\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.3401166632771492\n",
      "Valid loss 0.32185024619102476\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.3269445538520813\n",
      "Valid loss 0.3097836494445801\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.3197161704301834\n",
      "Valid loss 0.30385918021202085\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.31438700556755067\n",
      "Valid loss 0.30277132987976074\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.30874217599630355\n",
      "Valid loss 0.294893342256546\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.30297997742891314\n",
      "Valid loss 0.29104042053222656\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.3006133049726486\n",
      "Valid loss 0.28357459902763366\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.2950204014778137\n",
      "Valid loss 0.2807914078235626\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.2898833379149437\n",
      "Valid loss 0.2750311315059662\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.28528663963079454\n",
      "Valid loss 0.2730742275714874\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.28246611058712007\n",
      "Valid loss 0.26618642807006837\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.27877054214477537\n",
      "Valid loss 0.2651346743106842\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.27619450986385347\n",
      "Valid loss 0.26009404063224795\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.2713994339108467\n",
      "Valid loss 0.25641089379787446\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.2689616307616234\n",
      "Valid loss 0.2565660089254379\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.2655777782201767\n",
      "Valid loss 0.2529906749725342\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.2642915368080139\n",
      "Valid loss 0.24975918531417846\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.26122884452342987\n",
      "Valid loss 0.24817829132080077\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.2585473217070103\n",
      "Valid loss 0.24586423635482788\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.25643348023295404\n",
      "Valid loss 0.24447457790374755\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.25548946782946585\n",
      "Valid loss 0.24422982931137086\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.2521981254220009\n",
      "Valid loss 0.24029980301856996\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.2491179123520851\n",
      "Valid loss 0.23728685081005096\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.24783869683742524\n",
      "Valid loss 0.2363675206899643\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.24626192301511765\n",
      "Valid loss 0.23549732863903045\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.24391269832849502\n",
      "Valid loss 0.23293739855289458\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.24270540699362755\n",
      "Valid loss 0.23526181578636168\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.2421647399663925\n",
      "Valid loss 0.2312483847141266\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.23945906460285188\n",
      "Valid loss 0.23017367124557495\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.23886819928884506\n",
      "Valid loss 0.23056078851222991\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.23660772070288658\n",
      "Valid loss 0.22713811099529266\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.23496832624077796\n",
      "Valid loss 0.22802443504333497\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.23405888080596923\n",
      "Valid loss 0.2280638337135315\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.23493827506899834\n",
      "Valid loss 0.23022100031375886\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.23207609951496125\n",
      "Valid loss 0.22665838301181793\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.23059551268815995\n",
      "Valid loss 0.22733407616615295\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.2314866915345192\n",
      "Valid loss 0.22864165604114534\n",
      "#################\n",
      "###Epoch: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.23018686175346376\n",
      "Valid loss 0.2268580377101898\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.2292154885828495\n",
      "Valid loss 0.22333547472953796\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.22767195329070092\n",
      "Valid loss 0.2219638019800186\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.22575237303972245\n",
      "Valid loss 0.22072623670101166\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.2243036575615406\n",
      "Valid loss 0.22195352911949157\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.22720347940921784\n",
      "Valid loss 0.22165523171424867\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.22238143905997276\n",
      "Valid loss 0.22189440429210663\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.22111476138234137\n",
      "Valid loss 0.2182176321744919\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.22171741500496864\n",
      "Valid loss 0.2184634953737259\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.22038271352648736\n",
      "Valid loss 0.22101665437221527\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.21946285888552666\n",
      "Valid loss 0.21797596514225007\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.21765754744410515\n",
      "Valid loss 0.21666778028011321\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.21863870620727538\n",
      "Valid loss 0.2229464679956436\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.2175624206662178\n",
      "Valid loss 0.21754375100135803\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.21689799576997756\n",
      "Valid loss 0.21641944944858552\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.21531739309430123\n",
      "Valid loss 0.21821943521499634\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.21321482211351395\n",
      "Valid loss 0.216232767701149\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.21304916143417357\n",
      "Valid loss 0.21757327914237976\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.21188988015055657\n",
      "Valid loss 0.2142064541578293\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.211344575881958\n",
      "Valid loss 0.2165818452835083\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.21116499453783036\n",
      "Valid loss 0.2170112669467926\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.21056632250547408\n",
      "Valid loss 0.2146041601896286\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.20947561636567116\n",
      "Valid loss 0.2147485464811325\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.20820886939764022\n",
      "Valid loss 0.21299819946289061\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.20896711871027945\n",
      "Valid loss 0.21690785884857178\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.20875867381691932\n",
      "Valid loss 0.2172848105430603\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.20706656947731972\n",
      "Valid loss 0.2146553575992584\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.20585056245326996\n",
      "Valid loss 0.21312442421913147\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.20535178408026694\n",
      "Valid loss 0.21476636230945587\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.20494946241378784\n",
      "Valid loss 0.21172751486301422\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.2037465713918209\n",
      "Valid loss 0.213863405585289\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.20286512225866318\n",
      "Valid loss 0.21404552459716797\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.20248602107167243\n",
      "Valid loss 0.21316663026809693\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.20252995043992997\n",
      "Valid loss 0.21286305785179138\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.2019617609679699\n",
      "Valid loss 0.21171776354312896\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.2011020950973034\n",
      "Valid loss 0.21117134392261505\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.2004318431019783\n",
      "Valid loss 0.21359458565711975\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.2002245530486107\n",
      "Valid loss 0.2121899574995041\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.19933222085237504\n",
      "Valid loss 0.2119067519903183\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.1980839639902115\n",
      "Valid loss 0.21100255250930786\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.19730077534914017\n",
      "Valid loss 0.21028808355331421\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.197064621001482\n",
      "Valid loss 0.2103712022304535\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.19622838124632835\n",
      "Valid loss 0.21133936941623688\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.19663118571043015\n",
      "Valid loss 0.21032831966876983\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.1951170802116394\n",
      "Valid loss 0.2108472317457199\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.19469312205910683\n",
      "Valid loss 0.2101658344268799\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.19447326213121413\n",
      "Valid loss 0.20989472568035125\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.19334789514541625\n",
      "Valid loss 0.2094688206911087\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.19337057024240495\n",
      "Valid loss 0.21050445437431337\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.194029101729393\n",
      "Valid loss 0.21037856936454774\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.1926540404558182\n",
      "Valid loss 0.20952489376068115\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.1918057881295681\n",
      "Valid loss 0.2109600216150284\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.19144914597272872\n",
      "Valid loss 0.20927803218364716\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.19109811782836914\n",
      "Valid loss 0.208543062210083\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.1901671715080738\n",
      "Valid loss 0.2093339294195175\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.19071667790412902\n",
      "Valid loss 0.21054768264293672\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.19004776179790497\n",
      "Valid loss 0.2105439633131027\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.1887995980679989\n",
      "Valid loss 0.20783682763576508\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.18846693485975266\n",
      "Valid loss 0.2093602627515793\n",
      "Last 5 epoch train: 0.18963962882757188 - valid: 0.20952453315258027\n",
      "Last 10 epoch train: 0.19092343382537366 - valid: 0.2096307244896889\n",
      "Overall 5 last epoch train: 0.18735273006558417 - valid: 0.21818027722835542\n",
      "Overall 10 last epoch train: 0.18876180218160152 - valid: 0.21847909700870516\n",
      "OOF CV: 0.21773087978363037\n"
     ]
    }
   ],
   "source": [
    "splits = KFold(n_splits=config.n_split, shuffle=True, random_state=config.seed).split(train_inputs)\n",
    "# splits = StratifiedKFold(n_splits=config.n_split, shuffle=True, random_state=config.seed).split(train['id'], train['signal_to_noise'].apply(lambda x: int(x)))\n",
    "\n",
    "overall_5_train_loss = AverageMeter()\n",
    "overall_5_valid_loss = AverageMeter()\n",
    "\n",
    "overall_10_train_loss = AverageMeter()\n",
    "overall_10_valid_loss = AverageMeter()\n",
    "oof_label_all = None\n",
    "oof_pred_all = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(splits):\n",
    "    \n",
    "    train_dataset = TensorDataset(train_inputs[train_idx], train_adj[train_idx], train_labels[train_idx])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=8)\n",
    "    \n",
    "    valid_dataset = TensorDataset(train_inputs[val_idx], train_adj[val_idx], train_labels[val_idx])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=config.batch_size, shuffle=False, num_workers=8)\n",
    "    \n",
    "    train_losses, eval_losses, oof_label, oof_pred = run(fold, train_loader, valid_loader)\n",
    "    \n",
    "    if oof_label_all is None:\n",
    "        oof_label_all = oof_label\n",
    "        oof_pred_all = oof_pred\n",
    "    else:\n",
    "        oof_label_all = torch.cat([oof_label_all, oof_label], 0)\n",
    "        oof_pred_all = torch.cat([oof_pred_all, oof_pred], 0)\n",
    "    \n",
    "    last_5_train_loss = sum(train_losses[-5:])/len(train_losses[-5:])\n",
    "    last_5_valid_loss = sum(eval_losses[-5:])/len(eval_losses[-5:])\n",
    "    overall_5_train_loss.update(last_5_train_loss)\n",
    "    overall_5_valid_loss.update(last_5_valid_loss)\n",
    "    \n",
    "    last_10_train_loss = sum(train_losses[-10:])/len(train_losses[-10:])\n",
    "    last_10_valid_loss = sum(eval_losses[-10:])/len(eval_losses[-10:])\n",
    "    overall_10_train_loss.update(last_10_train_loss)\n",
    "    overall_10_valid_loss.update(last_10_valid_loss)\n",
    "    \n",
    "    print(f'Last 5 epoch train: {last_5_train_loss} - valid: {last_5_valid_loss}')\n",
    "    print(f'Last 10 epoch train: {last_10_train_loss} - valid: {last_10_valid_loss}')\n",
    "    \n",
    "print(f'Overall 5 last epoch train: {overall_5_train_loss.avg} - valid: {overall_5_valid_loss.avg}')\n",
    "print(f'Overall 10 last epoch train: {overall_10_train_loss.avg} - valid: {overall_10_valid_loss.avg}')\n",
    "print(f'OOF CV: {MCRMSE(oof_label_all, oof_pred_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overall 5 epoch train: 0.0451215458744102 - valid: 0.06322710109608513\n",
    "Overall 10 epoch train: 0.04563371909713303 - valid: 0.06327088166560445\n",
    "        \n",
    "Use BPP as weight adj matrix\n",
    "GRU\n",
    "Overall 5 epoch train: 0.0430864584280385 - valid: 0.06221413508057594\n",
    "Overall 10 epoch train: 0.04368967310146049 - valid: 0.06239632720393794\n",
    "LSTM\n",
    "Overall 5 last epoch train: 0.041662138899167374 - valid: 0.06205343489136015\n",
    "Overall 10 last epoch train: 0.042378014334374006 - valid: 0.06232069560459682\n",
    "GRU -> GCN\n",
    "Overall 5 last epoch train: 0.04252960059377882 - valid: 0.06481357118913104\n",
    "Overall 10 last epoch train: 0.04310291423841759 - valid: 0.0650169599056244\n",
    "SN_filter\n",
    "Last 5 epoch train: 0.03829054716974497 - valid: 0.054680862873792646\n",
    "Last 10 epoch train: 0.038869887720793486 - valid: 0.05474848434329033\n",
    "Overall 5 last epoch train: 0.03866128552705049 - valid: 0.055820192784070966\n",
    "Overall 10 last epoch train: 0.03917157341167331 - valid: 0.055871706023812286\n",
    "3 labels\n",
    "Overall 5 last epoch train: 0.033922446276992556 - valid: 0.05792523550987243\n",
    "Overall 10 last epoch train: 0.03448757581226528 - valid: 0.05792512205243111\n",
    "5 labels MCRMSE loss\n",
    "Overall 5 last epoch train: 0.18149467387795448 - valid: 0.21504289948940278\n",
    "Overall 10 last epoch train: 0.18257398997247218 - valid: 0.21543894702196117\n",
    "Overall 5 last epoch train: 0.18749359598755838 - valid: 0.21788148260116577\n",
    "Overall 10 last epoch train: 0.18864331699907777 - valid: 0.21844578289985658\n",
    "MCRMSE loss class\n",
    "Overall 5 last epoch train: 0.1900108553469181 - valid: 0.23267986249923706\n",
    "Overall 10 last epoch train: 0.1914477916508913 - valid: 0.23293828153610235\n",
    "Overall 5 last epoch train: 0.19669136756658553 - valid: 0.23536729907989504\n",
    "Overall 10 last epoch train: 0.19817317792773242 - valid: 0.23596047580242155\n",
    "\n",
    "GPU + adj + bpp\n",
    "Overall 5 last epoch train: 0.044193561888403364 - valid: 0.06220439549003328\n",
    "Overall 10 last epoch train: 0.0448748238619279 - valid: 0.06226083738463265\n",
    "        \n",
    "K = 2\n",
    "Use BPP as weight adj matrix\n",
    "Overall 5 last epoch train: 0.05076819153295623 - valid: 0.06468318649700709\n",
    "Overall 10 last epoch train: 0.051428089461944715 - valid: 0.06473811021872929\n",
    "        \n",
    "Convert BPP to adj matrix (1 and 0)\n",
    "Overall 5 last epoch train: 0.04308395972406422 - valid: 0.06330352274434907\n",
    "Overall 10 last epoch train: 0.0436869018221343 - valid: 0.06328786111303739\n",
    "        \n",
    "Conv aggregator\n",
    "Overall 5 last epoch train: 0.046746739074587824 - valid: 0.06578907604728426\n",
    "Overall 10 last epoch train: 0.047424182744213825 - valid: 0.06575814057673728\n",
    "        \n",
    "Pooling aggregator\n",
    "Overall 5 last epoch train: 0.04330202187928889 - valid: 0.06245726023401532\n",
    "Overall 10 last epoch train: 0.04384024161155577 - valid: 0.06253742285072802\n",
    "        \n",
    "learning_rate = 0.002\n",
    "Use BPP as weight adj matrix\n",
    "Mean aggregator\n",
    "Overall 5 last epoch train: 0.035587881477894615 - valid: 0.06147534329976354\n",
    "Overall 10 last epoch train: 0.03606973063890581 - valid: 0.06147345149091312\n",
    "\n",
    "learning_rate = 0.003\n",
    "Overall 5 last epoch train: 0.03372417225605912 - valid: 0.06138800899897303\n",
    "Overall 10 last epoch train: 0.034225094819234476 - valid: 0.0614313035777637\n",
    "        \n",
    "learning_rate = 0.005\n",
    "Overall 5 last epoch train: 0.03593841718026885 - valid: 0.06251461637871605\n",
    "Overall 10 last epoch train: 0.036377053264942436 - valid: 0.06247474372386932\n",
    "        \n",
    "learning_rate = 0.003\n",
    "No GCN\n",
    "Overall 5 last epoch train: 0.042106328460353386 - valid: 0.06521862102406364\n",
    "Overall 10 last epoch train: 0.042440810569182585 - valid: 0.06519380110715116\n",
    "        \n",
    "Dropout 0.2, with GCN\n",
    "Overall 5 last epoch train: 0.024202211432986794 - valid: 0.06166929091726031\n",
    "Overall 10 last epoch train: 0.024575392231345174 - valid: 0.06173114275293692\n",
    "\n",
    "Epoch 0\n",
    "Last 5 epoch train: 0.0329512511552484 - valid: 0.06581846997141838\n",
    "Last 10 epoch train: 0.03340453362023389 - valid: 0.06565298672233309"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=loss<br>epoch=%{x}<br>Mean Squared Error=%{y}<extra></extra>",
         "legendgroup": "loss",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x",
         "y": [
          0.48273690789937973,
          0.40723446011543274,
          0.3773126095533371,
          0.35939496010541916,
          0.33985656648874285,
          0.3273728832602501,
          0.3196266576647758,
          0.3137975618243217,
          0.308723421394825,
          0.3032114654779434,
          0.29994065761566163,
          0.2945294946432114,
          0.290300215780735,
          0.28435808420181274,
          0.2829069584608078,
          0.27774895280599593,
          0.2741455093026161,
          0.2709351062774658,
          0.2687768042087555,
          0.26739133447408675,
          0.26330714374780656,
          0.2606166049838066,
          0.25842836424708365,
          0.25635622441768646,
          0.25397512391209603,
          0.25310348644852637,
          0.2492508478462696,
          0.24776141867041587,
          0.2460443526506424,
          0.2437390886247158,
          0.2428310327231884,
          0.24135096818208696,
          0.23919962644577025,
          0.23875275403261184,
          0.2362913928925991,
          0.23414727300405502,
          0.23387048691511153,
          0.2341191552579403,
          0.23251587375998498,
          0.2308691218495369,
          0.23591210097074508,
          0.22911471202969552,
          0.22853080779314042,
          0.22686165571212769,
          0.22457200586795806,
          0.22418466657400132,
          0.22465002536773682,
          0.22261837124824524,
          0.22171866968274118,
          0.2202678620815277,
          0.2195429250597954,
          0.21930376440286636,
          0.2184830516576767,
          0.21789644211530684,
          0.21754343509674073,
          0.21720566004514694,
          0.215144781768322,
          0.21361960396170615,
          0.2129038579761982,
          0.2114792414009571,
          0.21052262485027312,
          0.21164432018995286,
          0.21076631769537926,
          0.20956745445728303,
          0.20814202576875687,
          0.20897048935294152,
          0.20824590548872948,
          0.20748597458004953,
          0.20695043429732324,
          0.20513138473033904,
          0.20441861897706987,
          0.20427499786019326,
          0.2038336768746376,
          0.20259216278791428,
          0.20195138603448867,
          0.20088661909103395,
          0.20146995931863784,
          0.20016878992319107,
          0.20009827837347985,
          0.20061422511935234,
          0.19836745411157608,
          0.19788386076688766,
          0.19673580825328826,
          0.19596910774707793,
          0.19637831524014474,
          0.19527721107006074,
          0.1951603874564171,
          0.19392759948968888,
          0.19388796016573906,
          0.19480371475219727,
          0.19465340226888656,
          0.1934766486287117,
          0.1922043114900589,
          0.19133990854024888,
          0.19099551886320115,
          0.19058192372322083,
          0.18989025801420212,
          0.18961038812994957,
          0.19058334156870843,
          0.18978565707802772
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=val_loss<br>epoch=%{x}<br>Mean Squared Error=%{y}<extra></extra>",
         "legendgroup": "val_loss",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "val_loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x",
         "y": [
          0.4223647236824036,
          0.37234044075012207,
          0.3558888673782349,
          0.33699079751968386,
          0.32127390503883363,
          0.3105610430240631,
          0.3038672685623169,
          0.3023068130016327,
          0.29515351057052613,
          0.2905090510845184,
          0.2831646382808685,
          0.27892316579818727,
          0.2757247269153595,
          0.274135959148407,
          0.26612393856048583,
          0.26362345814704896,
          0.25865119099617007,
          0.2556909084320068,
          0.2609039664268494,
          0.25486605167388915,
          0.24872734844684602,
          0.24676865339279175,
          0.24530128836631776,
          0.24378947913646698,
          0.24237297475337982,
          0.2403329223394394,
          0.23773458302021028,
          0.2371017962694168,
          0.23543391227722169,
          0.23331960141658784,
          0.23289721608161926,
          0.23058465719223023,
          0.23116243183612822,
          0.2295362740755081,
          0.22700656354427337,
          0.22766960561275482,
          0.22852603495121002,
          0.22775926291942597,
          0.22612145245075227,
          0.23426368832588196,
          0.22745491862297057,
          0.22474361658096315,
          0.22460854649543763,
          0.22193145453929902,
          0.22069245874881743,
          0.2216530203819275,
          0.22120445668697358,
          0.22277138829231263,
          0.21797327399253846,
          0.21855869889259338,
          0.21951479613780975,
          0.21793653666973115,
          0.2179367572069168,
          0.22208024561405182,
          0.21706855595111846,
          0.2156088560819626,
          0.21774936020374297,
          0.21662831902503968,
          0.21547542214393617,
          0.21487044990062715,
          0.2179531931877136,
          0.21750873029232026,
          0.2148006796836853,
          0.2147919565439224,
          0.21347866654396058,
          0.21728695631027223,
          0.21492140591144562,
          0.2138199657201767,
          0.2143043965101242,
          0.214493528008461,
          0.21280660331249238,
          0.2121839016675949,
          0.21209549605846406,
          0.21252281665802003,
          0.21204647421836853,
          0.21493280827999114,
          0.21396502554416658,
          0.21201314330101012,
          0.2143643319606781,
          0.21259163916110993,
          0.2107771873474121,
          0.2117871195077896,
          0.21047103106975557,
          0.21471762657165527,
          0.2109938830137253,
          0.21147899329662323,
          0.21186710894107819,
          0.2100423365831375,
          0.21058693528175354,
          0.2126210242509842,
          0.2122141808271408,
          0.21297085881233216,
          0.21201722621917723,
          0.21097026467323304,
          0.21044471561908723,
          0.20977350771427156,
          0.2101079136133194,
          0.2094230681657791,
          0.20929961502552033,
          0.21050646901130676
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training History"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Mean Squared Error"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"245b7a39-60b8-483f-a6a5-e0811f1aa879\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"245b7a39-60b8-483f-a6a5-e0811f1aa879\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '245b7a39-60b8-483f-a6a5-e0811f1aa879',\n",
       "                        [{\"hovertemplate\": \"variable=loss<br>epoch=%{x}<br>Mean Squared Error=%{y}<extra></extra>\", \"legendgroup\": \"loss\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"loss\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"xaxis\": \"x\", \"y\": [0.48273690789937973, 0.40723446011543274, 0.3773126095533371, 0.35939496010541916, 0.33985656648874285, 0.3273728832602501, 0.3196266576647758, 0.3137975618243217, 0.308723421394825, 0.3032114654779434, 0.29994065761566163, 0.2945294946432114, 0.290300215780735, 0.28435808420181274, 0.2829069584608078, 0.27774895280599593, 0.2741455093026161, 0.2709351062774658, 0.2687768042087555, 0.26739133447408675, 0.26330714374780656, 0.2606166049838066, 0.25842836424708365, 0.25635622441768646, 0.25397512391209603, 0.25310348644852637, 0.2492508478462696, 0.24776141867041587, 0.2460443526506424, 0.2437390886247158, 0.2428310327231884, 0.24135096818208696, 0.23919962644577025, 0.23875275403261184, 0.2362913928925991, 0.23414727300405502, 0.23387048691511153, 0.2341191552579403, 0.23251587375998498, 0.2308691218495369, 0.23591210097074508, 0.22911471202969552, 0.22853080779314042, 0.22686165571212769, 0.22457200586795806, 0.22418466657400132, 0.22465002536773682, 0.22261837124824524, 0.22171866968274118, 0.2202678620815277, 0.2195429250597954, 0.21930376440286636, 0.2184830516576767, 0.21789644211530684, 0.21754343509674073, 0.21720566004514694, 0.215144781768322, 0.21361960396170615, 0.2129038579761982, 0.2114792414009571, 0.21052262485027312, 0.21164432018995286, 0.21076631769537926, 0.20956745445728303, 0.20814202576875687, 0.20897048935294152, 0.20824590548872948, 0.20748597458004953, 0.20695043429732324, 0.20513138473033904, 0.20441861897706987, 0.20427499786019326, 0.2038336768746376, 0.20259216278791428, 0.20195138603448867, 0.20088661909103395, 0.20146995931863784, 0.20016878992319107, 0.20009827837347985, 0.20061422511935234, 0.19836745411157608, 0.19788386076688766, 0.19673580825328826, 0.19596910774707793, 0.19637831524014474, 0.19527721107006074, 0.1951603874564171, 0.19392759948968888, 0.19388796016573906, 0.19480371475219727, 0.19465340226888656, 0.1934766486287117, 0.1922043114900589, 0.19133990854024888, 0.19099551886320115, 0.19058192372322083, 0.18989025801420212, 0.18961038812994957, 0.19058334156870843, 0.18978565707802772], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=val_loss<br>epoch=%{x}<br>Mean Squared Error=%{y}<extra></extra>\", \"legendgroup\": \"val_loss\", \"line\": {\"color\": \"#EF553B\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"val_loss\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"xaxis\": \"x\", \"y\": [0.4223647236824036, 0.37234044075012207, 0.3558888673782349, 0.33699079751968386, 0.32127390503883363, 0.3105610430240631, 0.3038672685623169, 0.3023068130016327, 0.29515351057052613, 0.2905090510845184, 0.2831646382808685, 0.27892316579818727, 0.2757247269153595, 0.274135959148407, 0.26612393856048583, 0.26362345814704896, 0.25865119099617007, 0.2556909084320068, 0.2609039664268494, 0.25486605167388915, 0.24872734844684602, 0.24676865339279175, 0.24530128836631776, 0.24378947913646698, 0.24237297475337982, 0.2403329223394394, 0.23773458302021028, 0.2371017962694168, 0.23543391227722169, 0.23331960141658784, 0.23289721608161926, 0.23058465719223023, 0.23116243183612822, 0.2295362740755081, 0.22700656354427337, 0.22766960561275482, 0.22852603495121002, 0.22775926291942597, 0.22612145245075227, 0.23426368832588196, 0.22745491862297057, 0.22474361658096315, 0.22460854649543763, 0.22193145453929902, 0.22069245874881743, 0.2216530203819275, 0.22120445668697358, 0.22277138829231263, 0.21797327399253846, 0.21855869889259338, 0.21951479613780975, 0.21793653666973115, 0.2179367572069168, 0.22208024561405182, 0.21706855595111846, 0.2156088560819626, 0.21774936020374297, 0.21662831902503968, 0.21547542214393617, 0.21487044990062715, 0.2179531931877136, 0.21750873029232026, 0.2148006796836853, 0.2147919565439224, 0.21347866654396058, 0.21728695631027223, 0.21492140591144562, 0.2138199657201767, 0.2143043965101242, 0.214493528008461, 0.21280660331249238, 0.2121839016675949, 0.21209549605846406, 0.21252281665802003, 0.21204647421836853, 0.21493280827999114, 0.21396502554416658, 0.21201314330101012, 0.2143643319606781, 0.21259163916110993, 0.2107771873474121, 0.2117871195077896, 0.21047103106975557, 0.21471762657165527, 0.2109938830137253, 0.21147899329662323, 0.21186710894107819, 0.2100423365831375, 0.21058693528175354, 0.2126210242509842, 0.2122141808271408, 0.21297085881233216, 0.21201722621917723, 0.21097026467323304, 0.21044471561908723, 0.20977350771427156, 0.2101079136133194, 0.2094230681657791, 0.20929961502552033, 0.21050646901130676], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"title\": {\"text\": \"variable\"}, \"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Training History\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Mean Squared Error\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('245b7a39-60b8-483f-a6a5-e0811f1aa879');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(\n",
    "    pd.DataFrame([train_losses, eval_losses], index=['loss', 'val_loss']).T, \n",
    "    y=['loss', 'val_loss'], \n",
    "    labels={'index': 'epoch', 'value': 'Mean Squared Error'}, \n",
    "    title='Training History')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = test.query(\"seq_length == 107\").copy()\n",
    "private_df = test.query(\"seq_length == 130\").copy()\n",
    "\n",
    "public_inputs, public_adj = preprocess_inputs(public_df)\n",
    "private_inputs, private_adj = preprocess_inputs(private_df)\n",
    "\n",
    "public_inputs = torch.tensor(public_inputs, dtype=torch.long)\n",
    "private_inputs = torch.tensor(private_inputs, dtype=torch.long)\n",
    "public_adj = torch.tensor(public_adj, dtype=torch.long)\n",
    "private_adj = torch.tensor(private_adj, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_short = Net(seq_len=107, pred_len=107, K=config.K, aggregator=config.gcn_agg)\n",
    "model_long = Net(seq_len=130, pred_len=130, K=config.K, aggregator=config.gcn_agg)\n",
    "\n",
    "list_public_preds = []\n",
    "list_private_preds = []\n",
    "for fold in range(config.n_split):\n",
    "    model_short.load_state_dict(torch.load(f'{config.pretrain_dir}/gru_{fold}.pt'))\n",
    "    model_long.load_state_dict(torch.load(f'{config.pretrain_dir}/gru_{fold}.pt'))\n",
    "    model_short.cuda()\n",
    "    model_long.cuda()\n",
    "    model_short.eval()\n",
    "    model_long.eval()\n",
    "\n",
    "    public_preds = model_short(public_inputs.cuda(), public_adj.cuda())\n",
    "    private_preds = model_long(private_inputs.cuda(), private_adj.cuda())\n",
    "    public_preds = public_preds.cpu().detach().numpy()\n",
    "    private_preds = private_preds.cpu().detach().numpy()\n",
    "    \n",
    "    list_public_preds.append(public_preds)\n",
    "    list_private_preds.append(private_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_preds = np.mean(list_public_preds, axis=0)\n",
    "private_preds = np.mean(list_private_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ls = []\n",
    "\n",
    "for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "\n",
    "        single_df = pd.DataFrame(single_pred, columns=config.pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "        preds_ls.append(single_df)\n",
    "\n",
    "preds_df = pd.concat(preds_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "submission.to_csv(f'{config.data_dir}/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6 - 0.28785\n",
    "# 0.4 - 0.28630"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
